# FineTuning & Serving LLMs


Neural Networks and Deep Learning

Transformers and Attention Mechanism

Tokenization

Large Language Models

Pretraining --> Base Model Finetuning --> SFT, RLFH --> Chat Model

Tasks to Fine-Tune

How to finetune a LLM

Preparing finetuning Dataset

Some concepts to understand before we fine-tune and serve any LLM -

Supervised Fine-Tuning (SFT) LoRA QLoRA
Parameter Efficient Finetuning LoRA QLoRA Adaptors Prompt Tuning Prefix Tuning

Reinforcement Learning from Human Feedback(RLHF) PPO DPO

Compute and Memory requirements

Training Arguments

Training

Evaluation

Quantization
Types of Quantization Post-training Quantization (PTQ) - GPTQ, AWQ are classified as PTQ
Quantization-aware training (QAT)
GGUF(GGML)

Inference Optimization

Serving the model

Securing LLMs

Conclusions

References
