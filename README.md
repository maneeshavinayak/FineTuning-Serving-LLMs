# FineTuning & Serving LLMs


Neural Networks and Deep Learning

Transformers and Attention Mechanism

Tokenization

Large Language Models

Pretraining --> Base Model Finetuning --> SFT, RLFH --> Chat Model

Tasks to Fine-Tune

How to finetune a LLM

Preparing finetuning Dataset

Some concepts to understand before we fine-tune and serve any LLM -

Supervised Fine-Tuning (SFT) LoRA QLoRA

Reinforcement Learning from Human Feedback(RLHF) PPO DPO

Parameter Efficient Finetuning LoRA QLoRA Adaptors Prompt Tuning Prefix Tuning

Quantization

Types of Quantization Post-training Quantization (PTQ) GPTQ, AWQ are classified as PTQ

Quantization-aware training (QAT) QLoRA is classified as QAT

GGUF(GGML)

Compute and Memory requirements

Training Arguments

Training

Serving the model

Conclusions

References
